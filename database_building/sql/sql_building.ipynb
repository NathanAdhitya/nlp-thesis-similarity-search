{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc8948a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f6a3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    ")\n",
    "cursor = database.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef01c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS nlp_thesis_similarity\")\n",
    "cursor.execute(\"USE nlp_thesis_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0542f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main papers table\n",
    "create_papers_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dewey_papers (\n",
    "    id VARCHAR(50) PRIMARY KEY,\n",
    "    title TEXT NOT NULL,\n",
    "    abstract TEXT,\n",
    "    publisher VARCHAR(255),\n",
    "    language VARCHAR(50),\n",
    "    theme VARCHAR(255),\n",
    "    category VARCHAR(255),\n",
    "    sub_category VARCHAR(255),\n",
    "    source TEXT\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_papers_table)\n",
    "database.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9fbaa1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for creators (authors)\n",
    "create_creators_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS creators (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    UNIQUE(name)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_creators_table)\n",
    "\n",
    "# Create table for paper-creator relationships\n",
    "create_paper_creators_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS paper_creators (\n",
    "    paper_id VARCHAR(50),\n",
    "    creator_id INT,\n",
    "    PRIMARY KEY (paper_id, creator_id),\n",
    "    FOREIGN KEY (paper_id) REFERENCES dewey_papers(id),\n",
    "    FOREIGN KEY (creator_id) REFERENCES creators(id)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_paper_creators_table)\n",
    "database.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "664c3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for contributors (advisors, committee members)\n",
    "create_contributors_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS contributors (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    UNIQUE(name)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_contributors_table)\n",
    "\n",
    "# Create table for paper-contributor relationships with role information\n",
    "create_paper_contributors_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS paper_contributors (\n",
    "    paper_id VARCHAR(50),\n",
    "    contributor_id INT,\n",
    "    role VARCHAR(100),\n",
    "    PRIMARY KEY (paper_id, contributor_id, role),\n",
    "    FOREIGN KEY (paper_id) REFERENCES dewey_papers(id),\n",
    "    FOREIGN KEY (contributor_id) REFERENCES contributors(id)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_paper_contributors_table)\n",
    "database.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aea99e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for subjects/keywords\n",
    "create_subjects_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS subjects (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    UNIQUE(name)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_subjects_table)\n",
    "\n",
    "# Create table for paper-subject relationships\n",
    "create_paper_subjects_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS paper_subjects (\n",
    "    paper_id VARCHAR(50),\n",
    "    subject_id INT,\n",
    "    PRIMARY KEY (paper_id, subject_id),\n",
    "    FOREIGN KEY (paper_id) REFERENCES dewey_papers(id),\n",
    "    FOREIGN KEY (subject_id) REFERENCES subjects(id)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_paper_subjects_table)\n",
    "database.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024588ef",
   "metadata": {},
   "source": [
    "# Database Schema for NLP Thesis Similarity Analysis\n",
    "\n",
    "![Database ERD](./erd_sql.png)\n",
    "\n",
    "## Database Structure\n",
    "This notebook sets up a MySQL database for storing and analyzing academic papers. The schema includes:\n",
    "\n",
    "- **dewey_papers**: Stores the main paper information including title, abstract, publisher, and categorization\n",
    "- **creators**: Authors of the papers\n",
    "- **contributors**: Advisors and committee members with their roles\n",
    "- **subjects**: Keywords and subject areas related to papers\n",
    "\n",
    "The design uses junction tables (paper_creators, paper_contributors, paper_subjects) to establish many-to-many relationships between entities while maintaining data integrity through foreign key constraints.\n",
    "\n",
    "The database supports importing thesis data from JSON files, with functions to handle both individual and bulk imports from the dewey_thesis directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19a6fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to insert data from a JSON file\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to insert a paper from a JSON file\n",
    "def insert_paper_from_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        paper_data = json.load(file)\n",
    "    \n",
    "    # Insert into dewey_papers table\n",
    "    insert_paper = \"\"\"\n",
    "    INSERT INTO dewey_papers (id, title, abstract, publisher, language, theme, category, sub_category, source)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        title = VALUES(title),\n",
    "        abstract = VALUES(abstract),\n",
    "        publisher = VALUES(publisher),\n",
    "        language = VALUES(language),\n",
    "        theme = VALUES(theme),\n",
    "        category = VALUES(category),\n",
    "        sub_category = VALUES(sub_category),\n",
    "        source = VALUES(source)\n",
    "    \"\"\"\n",
    "    \n",
    "    paper_values = (\n",
    "        paper_data.get('id'),\n",
    "        paper_data.get('title'),\n",
    "        paper_data.get('abstract'),\n",
    "        paper_data.get('publisher'),\n",
    "        paper_data.get('language'),\n",
    "        paper_data.get('theme'),\n",
    "        paper_data.get('category'),\n",
    "        paper_data.get('sub_category'),\n",
    "        paper_data.get('source')\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(insert_paper, paper_values)\n",
    "        \n",
    "        # Process creators (authors)\n",
    "        if 'creators' in paper_data and paper_data['creators']:\n",
    "            creators_list = [creator.strip() for creator in paper_data['creators'].split(';') if creator.strip()]\n",
    "            if len(creators_list) == 1 and ';' not in paper_data['creators']:\n",
    "                creators_list = [paper_data['creators'].strip()]\n",
    "                \n",
    "            for creator_name in creators_list:\n",
    "                # Insert creator if not exists\n",
    "                cursor.execute(\"INSERT IGNORE INTO creators (name) VALUES (%s)\", (creator_name,))\n",
    "                cursor.execute(\"SELECT id FROM creators WHERE name = %s\", (creator_name,))\n",
    "                creator_id = cursor.fetchone()[0]\n",
    "                \n",
    "                # Link creator to paper\n",
    "                cursor.execute(\n",
    "                    \"INSERT IGNORE INTO paper_creators (paper_id, creator_id) VALUES (%s, %s)\",\n",
    "                    (paper_data.get('id'), creator_id)\n",
    "                )\n",
    "        \n",
    "        # Process contributors (advisors, committee members)\n",
    "        if 'contributors' in paper_data and paper_data['contributors']:\n",
    "            contributors_list = [contrib.strip() for contrib in paper_data['contributors'].split(';') if contrib.strip()]\n",
    "            \n",
    "            for contributor_info in contributors_list:\n",
    "                if '(' in contributor_info and ')' in contributor_info:\n",
    "                    # Extract name and role\n",
    "                    name_part, role_part = contributor_info.split('(', 1)\n",
    "                    contributor_name = name_part.strip()\n",
    "                    role = role_part.split(')', 1)[0].strip()\n",
    "                else:\n",
    "                    contributor_name = contributor_info\n",
    "                    role = \"Unknown\"\n",
    "                \n",
    "                # Insert contributor if not exists\n",
    "                cursor.execute(\"INSERT IGNORE INTO contributors (name) VALUES (%s)\", (contributor_name,))\n",
    "                cursor.execute(\"SELECT id FROM contributors WHERE name = %s\", (contributor_name,))\n",
    "                contributor_id = cursor.fetchone()[0]\n",
    "                \n",
    "                # Link contributor to paper with role\n",
    "                cursor.execute(\n",
    "                    \"INSERT IGNORE INTO paper_contributors (paper_id, contributor_id, role) VALUES (%s, %s, %s)\",\n",
    "                    (paper_data.get('id'), contributor_id, role)\n",
    "                )\n",
    "        \n",
    "        # Process subjects/keywords\n",
    "        if 'subjects' in paper_data and paper_data['subjects']:\n",
    "            subjects_list = [subject.strip() for subject in paper_data['subjects'].split(';') if subject.strip()]\n",
    "            if len(subjects_list) == 1 and ';' not in paper_data['subjects']:\n",
    "                subjects_list = [paper_data['subjects'].strip()]\n",
    "                \n",
    "            for subject_name in subjects_list:\n",
    "                # Insert subject if not exists\n",
    "                cursor.execute(\"INSERT IGNORE INTO subjects (name) VALUES (%s)\", (subject_name,))\n",
    "                cursor.execute(\"SELECT id FROM subjects WHERE name = %s\", (subject_name,))\n",
    "                subject_id = cursor.fetchone()[0]\n",
    "                \n",
    "                # Link subject to paper\n",
    "                cursor.execute(\n",
    "                    \"INSERT IGNORE INTO paper_subjects (paper_id, subject_id) VALUES (%s, %s)\",\n",
    "                    (paper_data.get('id'), subject_id)\n",
    "                )\n",
    "        \n",
    "        database.commit()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting paper {paper_data.get('id')}: {e}\")\n",
    "        database.rollback()\n",
    "        return False\n",
    "\n",
    "# Example usage with a single file\n",
    "# json_file_path = \"../../data/dewey_thesis/9000.json\"\n",
    "# result = insert_paper_from_json(json_file_path)\n",
    "# print(f\"Inserted paper from {json_file_path}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c25014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing papers: 100%|██████████| 41597/41597 [13:21<00:00, 51.90file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk import complete: 41597 papers imported successfully, 0 failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Bulk insert papers from the dewey_thesis folder\n",
    "def insert_all_papers_from_folder(folder_path):\n",
    "    # Import tqdm for progress bar\n",
    "    \n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Get list of JSON files first\n",
    "    json_files = [filename for filename in os.listdir(folder_path) if filename.endswith('.json')]\n",
    "    \n",
    "    # Use tqdm to show progress\n",
    "    for filename in tqdm(json_files, desc=\"Importing papers\", unit=\"file\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if insert_paper_from_json(file_path):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            failed += 1\n",
    "    \n",
    "    return successful, failed\n",
    "\n",
    "# Uncomment to run the bulk import\n",
    "# Note: This may take a while depending on the number of files\n",
    "dewey_thesis_folder = \"../../data/dewey_thesis\"\n",
    "successful, failed = insert_all_papers_from_folder(dewey_thesis_folder)\n",
    "print(f\"Bulk import complete: {successful} papers imported successfully, {failed} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "573062d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers in database: 41597\n",
      "\n",
      "Sample paper:\n",
      "ID: 1000\n",
      "Title: The Indonesian subtitles of the English utterances spoken by the characters in American Beauty\n",
      "Abstract: This thesis is particularly about the translation done on the subtitles of the movie entitled Americ...\n",
      "Creators: BERLIN RAHAYU\n",
      "Subjects: ENGLISH LANGUAGE-SLANG; ENGLISH LANGUAGE-TRANSLATING INTO INDONESIAN\n"
     ]
    }
   ],
   "source": [
    "# Query to test and verify the database structure\n",
    "def test_database_structure():\n",
    "    # Check the number of papers\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM dewey_papers\")\n",
    "    paper_count = cursor.fetchone()[0]\n",
    "    print(f\"Total papers in database: {paper_count}\")\n",
    "    \n",
    "    # Sample query to get a paper with its creators and subjects\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        p.id, p.title, p.abstract, \n",
    "        GROUP_CONCAT(DISTINCT c.name SEPARATOR '; ') as creators,\n",
    "        GROUP_CONCAT(DISTINCT s.name SEPARATOR '; ') as subjects\n",
    "    FROM \n",
    "        dewey_papers p\n",
    "    LEFT JOIN \n",
    "        paper_creators pc ON p.id = pc.paper_id\n",
    "    LEFT JOIN \n",
    "        creators c ON pc.creator_id = c.id\n",
    "    LEFT JOIN \n",
    "        paper_subjects ps ON p.id = ps.paper_id\n",
    "    LEFT JOIN \n",
    "        subjects s ON ps.subject_id = s.id\n",
    "    GROUP BY \n",
    "        p.id\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\nSample paper:\")\n",
    "        print(f\"ID: {result[0]}\")\n",
    "        print(f\"Title: {result[1]}\")\n",
    "        print(f\"Abstract: {result[2][:100]}...\")\n",
    "        print(f\"Creators: {result[3]}\")\n",
    "        print(f\"Subjects: {result[4]}\")\n",
    "    else:\n",
    "        print(\"No papers found in database\")\n",
    "\n",
    "# Run the test\n",
    "test_database_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ece2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Close the database connection when done\n",
    "# Uncomment when you're finished with the database\n",
    "cursor.close()\n",
    "database.close()\n",
    "print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-thesis-similarity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
